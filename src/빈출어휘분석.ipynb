{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgfkmDM/r3u6gY+Fr2F4ww",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piaoyanxiu/vocab-collocation/blob/main/%EC%9B%B9%ED%85%8D%EB%A7%88_%ED%94%8C%EC%A0%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmU95WgY5KUH",
        "outputId": "170404f4-3dfb-4080-8cd4-e0561c675759"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=966de50cbfc376053ecc753c6b2d9e4056981fd3c36de55663f4161a6a8a495e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qzmtmZKQFWif"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "import wget\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = requests.get('https://www.suneung.re.kr/boardCnts/list.do?boardID=1500236&m=0403&s=suneung&searchStr=')\n",
        "\n",
        "print(\"◎ 응답 코드: \", res.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmQux2V-FrAc",
        "outputId": "f5eed525-b32e-4ea9-d73b-3de3747e1ea8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "◎ 응답 코드:  200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup = bs(res.text)"
      ],
      "metadata": {
        "id": "mQ2lZN0cHF4y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for contents in soup.find_all('a'):\n",
        "  if 'title' in contents.attrs:\n",
        "    if \"영어\" in contents.attrs['title']:\n",
        "      if 'onclick' in contents.attrs :\n",
        "        print(contents)"
      ],
      "metadata": {
        "id": "6rNigZesKMvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efb2fd9-ac8d-43c4-bb28-ceea716fe8e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a href=\"#;\" onclick=\"fn_fileDown('6ae9013673bcc7226d19d536d337733c');\" title=\"영어영역_문제지.pdf\"><img alt=\"영어영역_문제지.pdf\" height=\"16\" src=\"/images/board/board_pdf.png\" width=\"16\"/> </a>\n",
            "<a href=\"#;\" onclick=\"fn_fileDown('a865be83814ad0de8806d3c5d6aef76c');\" title=\"영어영역듣기평가음원.zip\"><img alt=\"영어영역듣기평가음원.zip\" height=\"16\" src=\"/images/board/board_zip.png\" width=\"16\"/> </a>\n",
            "<a href=\"#;\" onclick=\"fn_fileDown('a8e37ec95dcf0c8a1640f198a1f4d6ff');\" title=\"영어영역듣기평가대본.pdf\"><img alt=\"영어영역듣기평가대본.pdf\" height=\"16\" src=\"/images/board/board_pdf.png\" width=\"16\"/> </a>\n",
            "<a href=\"#;\" onclick=\"fn_fileDown('b589da9509036b93560087955c79d5b0');\" title=\"영어영역_정답표.pdf\"><img alt=\"영어영역_정답표.pdf\" height=\"16\" src=\"/images/board/board_pdf.png\" width=\"16\"/> </a>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "links=[]\n",
        "\n",
        "def web_scraping(maxpage, start = 1):\n",
        "\n",
        "    maxpage=int(maxpage)\n",
        "    print ('maxpage = ', maxpage)\n",
        "    print()\n",
        "\n",
        "    while 1:\n",
        "\n",
        "        if start >= maxpage+1 :\n",
        "          break\n",
        "\n",
        "        org_url='https://www.kice.re.kr/boardCnts/'\n",
        "        url='https://www.suneung.re.kr/boardCnts/list.do?type=default&page={}&searchStr=&m=0403&C06=&boardID=1500236&C05=&C04=&C03=&C02=&searchType=S&C01=&s=suneung'.format(start)\n",
        "        req = requests.get(url)\n",
        "\n",
        "        page = bs(req.text, 'html.parser')\n",
        "\n",
        "        for link in page.find_all('a'):\n",
        "            title=link.get('title')\n",
        "            if (title==\"3교시_영어영역_문제지.pdf\") or (title==\"3교시_영어_문제지.pdf\") or (title==\"영어영역_문제지.pdf\"):\n",
        "               current_link=link.get('onclick')\n",
        "\n",
        "               if current_link is None:\n",
        "                 continue\n",
        "\n",
        "               if current_link.startswith('fn'):\n",
        "                  current_link=current_link.strip(\"');\")\n",
        "                  current_link=current_link.replace(\"fn_fileDown('\", \"fileDown.do?fileSeq=\")\n",
        "\n",
        "                  links.append(org_url+current_link)\n",
        "                  print(\"currentLink\", current_link)\n",
        "               else: False\n",
        "\n",
        "        start += 1\n",
        "\n",
        "    for link in links:\n",
        "          wget.download(link)\n"
      ],
      "metadata": {
        "id": "fdST-n5URnSl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxpage = input(\"◎ 검색할 최대 페이지수: \")\n",
        "print()\n",
        "\n",
        "web_scraping(maxpage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBZnkpnYUJnu",
        "outputId": "0e5d89ea-ede9-4aa2-e735-777a20959a98"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "◎ 검색할 최대 페이지수: 10\n",
            "\n",
            "maxpage =  10\n",
            "\n",
            "currentLink fileDown.do?fileSeq=6ae9013673bcc7226d19d536d337733c\n",
            "currentLink fileDown.do?fileSeq=59c8b2f202f30c56fdd1cc1931188bad\n",
            "currentLink fileDown.do?fileSeq=e04e90133b6f6553fecb1d8b78f91ad1\n",
            "currentLink fileDown.do?fileSeq=4f7b44eb981a8794fc79c490f7b4c01e\n",
            "currentLink fileDown.do?fileSeq=de4823f124caf56f82e18bba901f4159\n",
            "currentLink fileDown.do?fileSeq=daa793a99c83fa0ed1e4d11fb5203ad4\n",
            "currentLink fileDown.do?fileSeq=bffd4ecdecf411375d124d5cf8a934ca\n",
            "currentLink fileDown.do?fileSeq=1fa497168518a43c55753f7860d62a65\n",
            "currentLink fileDown.do?fileSeq=54419bf4091095ae780c57e8de51953a\n",
            "currentLink fileDown.do?fileSeq=91c10e0c7df16f84a32cd96beb2120fe\n",
            "currentLink fileDown.do?fileSeq=a98c125c9412db4fd89b322f93c7f908\n",
            "currentLink fileDown.do?fileSeq=55c0e33363dfbdca3e8616460dcab736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "file_path = \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n568VLKNLZnP",
        "outputId": "1e0f68dc-063f-4575-e706-76a06ffc25e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhkf6gnhQWkk",
        "outputId": "618f1702-c95a-4fab-d427-3b63390a7b9b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.8-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.8 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.8-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.8 PyMuPDFb-1.24.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/3%EA%B5%90%EC%8B%9C_%EC%98%81%EC%96%B4%EC%98%81%EC%97%AD_%EB%AC%B8%EC%A0%9C%EC%A7%80 (1).pdf\n",
        "#/content/3%EA%B5%90%EC%8B%9C_%EC%98%81%EC%96%B4%EC%98%81%EC%97%AD_%EB%AC%B8%EC%A0%9C%EC%A7%80 (2).pdf\n",
        "\n",
        "import os\n",
        "import fitz\n",
        "import re\n",
        "\n",
        "filename=[]\n",
        "engl_text=[]\n",
        "texts='a'\n",
        "\n",
        "file_list=os.listdir(file_path)\n",
        "#print(file_list)\n",
        "\n",
        "for file in file_list:\n",
        "  if file.endswith('.pdf'):\n",
        "    filepath=os.path.join(file_path, file)\n",
        "    data=fitz.open(filepath)\n",
        "    for page in data:\n",
        "      text=page.get_text()\n",
        "      engl_text=re.sub('[^a-zA-Z ]',' ',text)\n",
        "      texts=texts+engl_text\n",
        "\n",
        "\n",
        "print(len(texts))"
      ],
      "metadata": {
        "id": "RieRKWvn-Zjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d1d6b3-5c63-4a9c-dc05-f3976e19c89c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "308173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "c_vector = CountVectorizer()\n",
        "engl_text=[engl_text]\n",
        "c_vector.fit_transform(engl_text)\n",
        "\n",
        "print('▶ 출현 단어: ', c_vector.get_feature_names_out())\n",
        "print(len(c_vector.get_feature_names_out()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0E-M9JYO_vh",
        "outputId": "ae2b993b-63df-4083-89dd-e210f1e7f781"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶ 출현 단어:  ['able' 'access' 'ace' 'additional' 'addressed' 'advised' 'after' 'all'\n",
            " 'allocate' 'allocation' 'also' 'am' 'amusement' 'an' 'and' 'andes'\n",
            " 'applied' 'are' 'arises' 'as' 'ashamed' 'asked' 'associated' 'at'\n",
            " 'attentively' 'auction' 'away' 'be' 'become' 'been' 'bought' 'brag'\n",
            " 'bragged' 'bribe' 'bribed' 'but' 'by' 'bypassed' 'can' 'capture'\n",
            " 'classmate' 'collect' 'combined' 'communities' 'community'\n",
            " 'congratulated' 'congratulations' 'constitutes' 'contest' 'crop' 'crops'\n",
            " 'cultivation' 'dad' 'debates' 'decided' 'decrease' 'delivered' 'derived'\n",
            " 'desert' 'development' 'disappointed' 'disclosed' 'do' 'don' 'done'\n",
            " 'economic' 'end' 'ensures' 'ensuring' 'envelope' 'essay' 'etc' 'example'\n",
            " 'excited' 'eyes' 'fair' 'favours' 'feel' 'felt' 'fill' 'first' 'flash'\n",
            " 'floods' 'foolish' 'for' 'found' 'free' 'from' 'front' 'full' 'go' 'gone'\n",
            " 'government' 'grants' 'grow' 'guaranteed' 'had' 'hadn' 'handed'\n",
            " 'harvested' 'has' 'have' 'he' 'hear' 'heard' 'her' 'hero' 'hesitant'\n",
            " 'him' 'his' 'hold' 'home' 'hooray' 'house' 'however' 'hundred' 'if'\n",
            " 'importance' 'in' 'individuals' 'irrigation' 'is' 'islamic' 'it' 'its'\n",
            " 'joy' 'kept' 'knew' 'know' 'land' 'law' 'letter' 'libnah' 'light'\n",
            " 'likewise' 'listening' 'long' 'longer' 'looked' 'mail' 'many' 'may'\n",
            " 'measure' 'methods' 'minute' 'miserable' 'mistakenly' 'moment' 'more'\n",
            " 'morning' 'mountain' 'my' 'name' 'never' 'new' 'next' 'night' 'no'\n",
            " 'nobody' 'not' 'notified' 'of' 'on' 'once' 'one' 'only' 'opened' 'or'\n",
            " 'out' 'overly' 'park' 'participated' 'partly' 'pay' 'per' 'perhaps'\n",
            " 'peru' 'picked' 'planned' 'pleased' 'possession' 'prize' 'proud'\n",
            " 'puzzled' 'quiet' 'rather' 'read' 'reading' 'real' 'realized' 'really'\n",
            " 'recently' 'recognized' 'reforms' 'regions' 'regretfully' 'remembered'\n",
            " 'requires' 'right' 'rights' 'runoff' 'said' 'saw' 'school' 'secret'\n",
            " 'separated' 'separately' 'share' 'she' 'should' 'shouted' 'sister'\n",
            " 'sitting' 'situation' 'sleep' 'slipped' 'so' 'sold' 'son' 'soon' 'source'\n",
            " 'sources' 'stable' 'stairs' 'started' 'state' 'status' 'stephanie'\n",
            " 'steps' 'steven' 'storage' 'strategies' 'subject' 'subsistence'\n",
            " 'substantial' 'supplies' 'supply' 'tasah' 'tears' 'tell' 'terribly'\n",
            " 'than' 'that' 'the' 'them' 'then' 'there' 'therefore' 'thing' 'this'\n",
            " 'thoroughly' 'those' 'thought' 'thrilled' 'through' 'throughout' 'thus'\n",
            " 'tickets' 'tied' 'to' 'took' 'trading' 'traditional' 'transferred' 'two'\n",
            " 'uncertain' 'unending' 'unfortunately' 'unit' 'until' 'up' 'use' 'very'\n",
            " 'vs' 'wait' 'wanted' 'was' 'water' 'way' 'we' 'wells' 'were' 'what'\n",
            " 'when' 'where' 'which' 'while' 'who' 'wholeheartedly' 'will' 'win'\n",
            " 'winked' 'winner' 'with' 'without' 'won' 'word' 'words' 'would' 'wrong'\n",
            " 'year' 'yemen' 'you' 'younger']\n",
            "304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('book')\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "metadata": {
        "id": "LnNVUAKv33Yv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfw_url='https://sightwords.com/sight-words/fry/'\n",
        "\n",
        "hfw_req = requests.get(hfw_url)\n",
        "\n",
        "hfw_page = bs(hfw_req.text, 'html.parser')\n"
      ],
      "metadata": {
        "id": "EvK9OB1dQMIQ",
        "collapsed": true
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hfw = hfw_page.find_all(attrs='pdf')[0]\n",
        "\n",
        "#print(hfw)\n",
        "\n",
        "grade1=hfw.find_all('li')[0].get_text()\n",
        "grade2=hfw.find_all('li')[1].get_text()\n",
        "grade3=hfw.find_all('li')[2].get_text()\n",
        "\n",
        "#print(grade)\n",
        "\n",
        "grades=grade1+grade2+grade3\n",
        "\n",
        "#hfws=grade.get_text()\n",
        "\n",
        "hfws=str(grades)\n",
        "hfws=re.sub('[^a-zA-Z ]','',hfws)\n",
        "hfws=hfws.replace(\"Fry Sight Words\",\"\")\n"
      ],
      "metadata": {
        "id": "ACaVU2fUQy1k"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "hfw_tokens=word_tokenize(hfws)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "alphabet=['a','b','c', 'd', 'e']\n",
        "number=['one','two','three']\n",
        "\n",
        "texts_lower=texts.lower()\n",
        "\n",
        "word_tokens = word_tokenize(texts_lower)\n",
        "\n",
        "result = []\n",
        "for word in word_tokens:\n",
        "    if word not in stop_words:\n",
        "      if word not in alphabet:\n",
        "        if word not in number:\n",
        "          if word not in hfw_tokens:\n",
        "            result.append(word)\n",
        "\n",
        "print(len(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5zDRa9dBMZn",
        "outputId": "ec03afe2-8dbc-45ec-fe19-a4d676b49042"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import pos_tag\n",
        "\n",
        "tagged_list = pos_tag(result)\n",
        "\n",
        "nouns_list = [tag[0] for tag in tagged_list if tag[1] == \"NNS\"]\n",
        "verbs_list = [tag[0] for tag in tagged_list if tag[1] == \"VBD\" or tag[1] == \"VBG\" or tag[1] == \"VBN\" or tag[1] == \"VBP\" or tag[1] == \"VBZ\"]\n",
        "adj_list=[tag[0] for tag in tagged_list if tag[1] == \"JJS\"]\n",
        "others_list = [tag[0] for tag in tagged_list if tag[1] != \"NNS\" and tag[1] != \"VBD\" and tag[1] != \"VBG\" and tag[1] != \"VBN\" and tag[1] != \"VBP\" and tag[1] != \"VBZ\" and tag[1] != \"JJS\"]\n"
      ],
      "metadata": {
        "id": "OKcLsztSU_Q1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wnlm = WordNetLemmatizer()\n",
        "\n",
        "noun_l=[wnlm.lemmatize(wd, pos=\"n\") for wd in nouns_list]\n",
        "verb_l=[wnlm.lemmatize(wd, pos=\"v\") for wd in verbs_list]\n",
        "adj_l=[wnlm.lemmatize(wd, pos=\"a\") for wd in adj_list]\n",
        "\n",
        "lemmas=noun_l+verb_l+adj_l+others_list\n",
        "\n",
        "len(lemmas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9EJfT-QQ836",
        "outputId": "f3658fae-c444-4e80-aeaa-a0d0f2b11546"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19541"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "counts = Counter(lemmas)\n",
        "\n",
        "words = counts.most_common(100)\n",
        "\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o13pcQYUBR9t",
        "outputId": "286dfd64-5724-4535-e7bb-06067155740f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('social', 82), ('information', 67), ('become', 66), ('human', 59), ('process', 59), ('individual', 52), ('experience', 51), ('problem', 47), ('however', 45), ('cultural', 44), ('make', 41), ('others', 40), ('culture', 40), ('activity', 40), ('age', 40), ('provide', 40), ('product', 39), ('sally', 38), ('music', 37), ('student', 34), ('way', 33), ('material', 33), ('value', 33), ('know', 33), ('give', 32), ('room', 31), ('feel', 31), ('cause', 30), ('result', 30), ('animal', 30), ('view', 30), ('art', 30), ('present', 30), ('p', 30), ('look', 30), ('better', 30), ('effect', 29), ('plant', 29), ('data', 29), ('service', 29), ('decision', 29), ('really', 29), ('benefit', 28), ('event', 28), ('system', 28), ('performance', 28), ('allow', 28), ('consider', 28), ('share', 28), ('rather', 28), ('science', 27), ('class', 27), ('understand', 27), ('require', 27), ('use', 27), ('knowledge', 27), ('self', 27), ('call', 26), ('base', 26), ('include', 26), ('ask', 26), ('best', 26), ('particular', 26), ('behavior', 25), ('change', 25), ('lead', 25), ('work', 25), ('develop', 25), ('create', 25), ('focus', 25), ('sense', 25), ('less', 25), ('today', 25), ('issue', 24), ('level', 24), ('interest', 24), ('cost', 24), ('community', 24), ('take', 24), ('need', 23), ('fact', 23), ('show', 23), ('participant', 23), ('mind', 23), ('society', 23), ('team', 23), ('control', 23), ('personal', 23), ('note', 22), ('environment', 22), ('object', 22), ('population', 22), ('produce', 22), ('appear', 22), ('public', 22), ('per', 22), ('likely', 22), ('goal', 21), ('waste', 21), ('development', 21)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "challenge=counts.most_common(1000)\n",
        "challenge[-30:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgz6vyOnGav7",
        "outputId": "8f64958e-cdb3-431c-bce4-b054fa17c638"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('creation', 5),\n",
              " ('ethic', 5),\n",
              " ('food', 5),\n",
              " ('regulation', 5),\n",
              " ('superior', 5),\n",
              " ('assumes', 5),\n",
              " ('grain', 5),\n",
              " ('anthropologist', 5),\n",
              " ('domain', 5),\n",
              " ('root', 5),\n",
              " ('habit', 5),\n",
              " ('rate', 5),\n",
              " ('end', 5),\n",
              " ('chain', 5),\n",
              " ('mechanism', 5),\n",
              " ('attack', 5),\n",
              " ('economics', 5),\n",
              " ('treatment', 5),\n",
              " ('expectation', 5),\n",
              " ('outcome', 5),\n",
              " ('destination', 5),\n",
              " ('machine', 5),\n",
              " ('quality', 5),\n",
              " ('ecosystem', 5),\n",
              " ('mammal', 5),\n",
              " ('consideration', 5),\n",
              " ('character', 5),\n",
              " ('bag', 5),\n",
              " ('stone', 5),\n",
              " ('pool', 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}
